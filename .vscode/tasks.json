{
  "version": "2.0.0",
  "tasks": [
    {
      "label": "Aspect Code: Build Extension",
      "type": "shell",
      "command": "npm run compile",
      "options": { "cwd": "${workspaceFolder}/extension" },
      "problemMatcher": "$tsc"
    },
    {
      "label": "Aspect Code: Start Server",
      "type": "shell",
      "command": "${config:python.defaultInterpreterPath} -m uvicorn app.main:app --host 127.0.0.1 --port 8000 --reload",
      "options": { "cwd": "${workspaceFolder}/server" },
      "isBackground": true
    },
    {
      "label": "Aspect Code: Open Playground (tiny)",
      "type": "shell",
      "command": "code -n ${env:Aspect Code_PLAYGROUND}/workspaces/tiny/fake",
      "problemMatcher": []
    },
    {
      "label": "SWE: Run single task",
      "type": "shell",
      "command": "${config:python.defaultInterpreterPath}",
      "args": [
        "-m",
        "playground.swebench.runner.run_task",
        "--task-file",
        "${input:TaskFile}",
        "--autofix",
        "--artifacts",
        "${workspaceFolder}/playground/swebench/_artifacts"
      ],
      "options": {
        "cwd": "${workspaceFolder}"
      },
      "group": "build",
      "presentation": {
        "echo": true,
        "reveal": "always",
        "focus": false,
        "panel": "shared"
      },
      "problemMatcher": []
    },
    {
      "label": "SWE: Run batch (llm_guarded)",
      "type": "shell", 
      "command": "${config:python.defaultInterpreterPath}",
      "args": [
        "-m",
        "playground.swebench.runner.run_batch",
        "--tasks",
        "${workspaceFolder}/playground/swebench/tasks/sample_tasks.json",
        "--strategy",
        "llm_guarded",
        "--provider",
        "${input:LLMProvider}",
        "--model",
        "${input:LLMModel}",
        "--k",
        "8",
        "--autofix",
        "--parallel",
        "2",
        "--eval"
      ],
      "options": {
        "cwd": "${workspaceFolder}"
      },
      "group": "build",
      "presentation": {
        "echo": true,
        "reveal": "always", 
        "focus": false,
        "panel": "shared"
      },
      "problemMatcher": []
    },
    {
      "label": "SWE: Run single task (agent mode)",
      "type": "shell",
      "command": "${config:python.defaultInterpreterPath}",
      "args": [
        "-m",
        "playground.swebench.runner.run_task",
        "--task-file",
        "${input:TaskFile}",
        "--strategy",
        "llm_guarded",
        "--provider",
        "${input:LLMProvider}",
        "--model",
        "${input:LLMModel}",
        "--k",
        "4",
        "--autofix",
        "--debug",
        "--artifacts",
        "${workspaceFolder}/playground/swebench/_artifacts"
      ],
      "options": {
        "cwd": "${workspaceFolder}"
      },
      "group": "build",
      "presentation": {
        "echo": true,
        "reveal": "always",
        "focus": false,
        "panel": "shared"
      },
      "problemMatcher": []
    },
    {
      "label": "SWE: Evaluate predictions.jsonl",
      "type": "shell",
      "command": "${config:python.defaultInterpreterPath}",
      "args": [
        "-m",
        "playground.swebench.runner.evaluator",
        "${workspaceFolder}/playground/swebench/_artifacts/predictions.jsonl"
      ],
      "options": {
        "cwd": "${workspaceFolder}"
      },
      "group": "build",
      "presentation": {
        "echo": true,
        "reveal": "always",
        "focus": false,
        "panel": "shared"
      },
      "problemMatcher": []
    },
    {
      "label": "SWE: Build evaluator image",
      "type": "shell",
      "command": "docker",
      "args": [
        "build",
        "-t",
        "Aspect Code-sweb-eval", 
        "-f",
        "playground/swebench/docker/evaluator.Dockerfile",
        "."
      ],
      "options": {
        "cwd": "${workspaceFolder}"
      },
      "group": "build",
      "presentation": {
        "echo": true,
        "reveal": "always",
        "focus": false,
        "panel": "shared"
      },
      "problemMatcher": []
    }
  ],
  "inputs": [
    {
      "id": "TaskFile",
      "type": "promptString",
      "description": "Path to a task JSON file",
      "default": "playground/swebench/examples/requests_import_cleanup.json"
    },
    {
      "id": "LLMProvider",
      "type": "pickString",
      "description": "LLM Provider",
      "options": [
        "openai",
        "anthropic", 
        "ollama"
      ],
      "default": "openai"
    },
    {
      "id": "LLMModel",
      "type": "promptString",
      "description": "LLM Model name",
      "default": "gpt-4o-mini"
    }
  ]
}
