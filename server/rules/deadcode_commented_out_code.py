# server/rules/deadcode_commented_out_code.py
"""
Rule: deadcode.commented_out_code

Detects blocks of commented-out code using lightweight heuristics and provides
suggested deletion patches (no direct edits).
"""

try:
    from ..engine.types import Rule, Finding, RuleMeta, Requires, RuleContext, Edit
except ImportError:
    from engine.types import Rule, Finding, RuleMeta, Requires, RuleContext, Edit

import re
from typing import List, Optional, Tuple, Dict, Any

# Per-language quick keyword sets (not exhaustiveâ€”heuristic only)
KW = {
    "python": {"def","class","import","from","if","elif","else","for","while","try","except","with","return","yield","async","await"},
    "javascript": {"function","class","if","else","for","while","try","catch","import","export","return","const","let","var","switch","case"},
    "typescript": {"function","class","interface","type","enum","if","else","for","while","try","catch","import","export","return","const","let"},
    "go": {"func","package","import","if","for","switch","case","type","struct","interface","return"},
    "java": {"class","interface","enum","if","else","for","while","try","catch","import","package","return","public","private","protected","static","final","new"},
    "csharp": {"class","struct","interface","enum","if","else","for","while","try","catch","using","namespace","return","public","private","protected","static","new"},
    "cpp": {"class","struct","if","else","for","while","try","catch","return","namespace","include","template","typedef","using","enum"},
    "c": {"if","else","for","while","return","#include","typedef","struct","enum"},
    "ruby": {"def","class","module","if","elsif","else","end","begin","rescue","require","return"},
    "rust": {"fn","struct","enum","impl","use","mod","if","else","match","loop","for","while","return","pub","let"},
    "swift": {"func","class","struct","enum","if","else","for","while","do","catch","import","return","let","var"},
}

# Regex cues that strongly indicate code-like text inside comments
CODE_CUES = re.compile(
    r"(?:\bif\b|\bfor\b|\bwhile\b|\breturn\b|\bclass\b|\bdef\b|\bfunc\b|\bfn\b|\bstruct\b|\benum\b|\bimport\b|\blet\b|\bconst\b|\bvar\b)"
    r"|[{}();=:>\[\]]"
)

# Lines to ignore (look like headers, docs, or metadata)
IGNORE_CUES = re.compile(
    r"(?:^|\s)(TODO|FIXME|NOTE|HACK|BUG|Docs?|Copyright|MIT|Apache|License|Generated by)\b",
    re.IGNORECASE
)

class DeadcodeCommentedOutCodeRule:
    """Detect blocks of commented-out code and suggest removing them."""
    
    meta = RuleMeta(
        id="deadcode.commented_out_code",
        category="deadcode",
        tier=0,  # Syntax only
        priority="P2",
        autofix_safety="suggest-only",
        description="Detect blocks of commented-out code and suggest removing them.",
        langs=["python", "typescript", "javascript", "go", "java", "cpp", "c", "csharp", "ruby", "rust", "swift"]
    )

    requires = Requires(
        raw_text=True,
        syntax=True,
        scopes=False,
        project_graph=False
    )

    def visit(self, ctx: RuleContext) -> List[Finding]:
        """Find commented-out code blocks in the file."""
        findings = []
        
        # Basic language check using file extension
        supported_extensions = {
            'py': 'python', 'ts': 'typescript', 'js': 'javascript', 
            'go': 'go', 'java': 'java', 'cpp': 'cpp', 'c': 'c', 
            'cs': 'csharp', 'rb': 'ruby', 'rs': 'rust', 'swift': 'swift'
        }
        
        file_ext = ctx.file_path.split('.')[-1].lower() if '.' in ctx.file_path else ''
        language = supported_extensions.get(file_ext, 'unknown')
        
        if language not in self.meta.langs:
            return findings

        tokens = self._get_tokens_from_tree(ctx)
        comment_blocks = self._group_consecutive_comments(tokens, ctx.text)

        for block in comment_blocks:
            start_b = block[0]['start_byte']
            end_b = block[-1]['end_byte']
            if not self._looks_like_code(language, block):
                continue

            diff, rationale = self._build_delete_suggestion(ctx, start_b, end_b)
            
            finding = Finding(
                rule=self.meta.id,
                message="Commented-out code detected. Consider removing dead code or uncommenting if still needed.",
                file=ctx.file_path,
                start_byte=start_b,
                end_byte=end_b,
                severity="info",
                autofix=None,  # suggest-only, no direct edits
                meta={
                    "category": self.meta.category,
                    "priority": self.meta.priority,
                    "diff": diff,
                    "rationale": rationale,
                    "language": language
                }
            )
            findings.append(finding)
        
        return findings

    def _get_tokens_from_tree(self, ctx: RuleContext) -> List[Dict[str, Any]]:
        """Extract tokens from the syntax tree."""
        tokens = []
        
        def traverse_node(node):
            # If this node has children, traverse them
            if hasattr(node, 'children') and node.children:
                for child in node.children:
                    traverse_node(child)
            else:
                # This is a leaf node (token)
                tokens.append({
                    'text': node.text,
                    'type': node.type,
                    'start_byte': node.start_byte,
                    'end_byte': node.end_byte,
                    'start_point': getattr(node, 'start_point', (0, 0)),
                    'end_point': getattr(node, 'end_point', (0, 0))
                })
        
        if ctx.tree and hasattr(ctx.tree, 'root_node'):
            traverse_node(ctx.tree.root_node)
        
        return tokens

    def _group_consecutive_comments(self, tokens, text):
        """Return list of blocks; each block is a list of adjacent comment tokens (including // /* */ #)."""
        blocks, cur = [], []
        prev_end = None
        text_bytes = text.encode('utf-8')
        
        for t in tokens:
            ttype = (t['type'] or "").lower()
            if "comment" in ttype:
                # Start new block if there's a blank line gap (double newline)
                if cur and prev_end is not None:
                    gap_start = prev_end
                    gap_end = t['start_byte']
                    if gap_end > gap_start:
                        # Check if gap contains multiple newlines (indicates blank line)
                        gap_text = text_bytes[gap_start:gap_end].decode('utf-8', 'ignore')
                        newline_count = gap_text.count('\n')
                        if newline_count >= 2:  # Blank line between comments
                            blocks.append(cur)
                            cur = []
                cur.append(t)
                prev_end = t['end_byte']
            else:
                if cur:
                    blocks.append(cur)
                    cur = []
                prev_end = None
        if cur:
            blocks.append(cur)
        return blocks

    def _looks_like_code(self, lang, block):
        """Heuristic scoring based on keywords, syntax cues, and character mix."""
        text = b"\n".join(t['text'] for t in block).decode("utf-8", "ignore")
        # Ignore documentation-like blocks
        if IGNORE_CUES.search(text):
            return False

        # Strip leading comment markers
        lines = [re.sub(r"^\s*(//+|/\*+|\*+|#+)\s?", "", ln) for ln in text.splitlines()]
        body = "\n".join(lines)

        # Signal 1: code cues present
        cues = len(CODE_CUES.findall(body))

        # Signal 2: language keywords present
        kws = KW.get(lang, set())
        kw_hits = sum(1 for w in kws if re.search(rf"\b{re.escape(w)}\b", body))

        # Signal 3: punctuation ratio typical of code
        punct = len(re.findall(r"[{}();,:=\[\]<>]", body))
        alpha = len(re.findall(r"[A-Za-z0-9_]", body))
        ratio = (punct / max(1, alpha))

        # Signal 4: line endings that look like statements
        stmt_like = len(re.findall(r";\s*$", body, flags=re.M))

        score = cues + kw_hits + stmt_like + (1 if ratio > 0.15 else 0)
        # Require minimum lines to avoid single-line false positives
        min_lines = 2
        return score >= 3 and len(lines) >= min_lines

    def _build_delete_suggestion(self, ctx, start_b, end_b):
        b = ctx.text.encode('utf-8')
        ls = b.rfind(b"\n", 0, start_b) + 1
        le = b.find(b"\n", end_b)
        if le == -1:
            le = len(b)

        before = b[ls:le].decode("utf-8", "ignore")
        after = (
            b[ls:start_b].decode("utf-8", "ignore")
            + b[end_b:le].decode("utf-8", "ignore")
        )

        diff = (
            "--- a/comments\n"
            "+++ b/comments\n"
            f"-{before}\n"
            f"+{after}\n"
        )
        rationale = "Remove commented-out code to reduce noise. If needed later, rely on version control history."
        return diff, rationale


# Register the rule
try:
    from ..engine.registry import register_rule
    from . import register
    register_rule(DeadcodeCommentedOutCodeRule())  # Global registry
    register(DeadcodeCommentedOutCodeRule())       # Local RULES list
except ImportError:
    from engine.registry import register_rule
    from rules import register
    register_rule(DeadcodeCommentedOutCodeRule())  # Global registry
    register(DeadcodeCommentedOutCodeRule())       # Local RULES list


